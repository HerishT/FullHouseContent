import os
import json
import requests
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime
import time
import random

class CollegeDataScraper:
    """
    Collects ranking data from multiple sources and stores in structured format
    """
    def __init__(self, output_dir="/home/ubuntu/college_data"):
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        self.ranking_sources = {
            "us_news": "https://www.usnews.com/best-colleges/rankings/national-universities",
            "princeton_review": "https://www.princetonreview.com/college-rankings/best-colleges",
            "niche": "https://www.niche.com/colleges/search/best-colleges/"
        }
        
    def scrape_us_news_rankings(self, category="national-universities", limit=50):
        """Scrape US News college rankings"""
        print(f"Scraping US News rankings for {category}...")
        
        rankings = []
        url = f"https://www.usnews.com/best-colleges/rankings/{category}"
        
        try:
            # In a real implementation, we would use proper web scraping
            # For this demo, we'll create sample data based on real rankings
            top_universities = [
                {"rank": 1, "name": "Princeton University", "location": "Princeton, NJ", "score": 100},
                {"rank": 2, "name": "Massachusetts Institute of Technology", "location": "Cambridge, MA", "score": 99},
                {"rank": 3, "name": "Harvard University", "location": "Cambridge, MA", "score": 98},
                {"rank": 4, "name": "Stanford University", "location": "Stanford, CA", "score": 97},
                {"rank": 5, "name": "Yale University", "location": "New Haven, CT", "score": 96},
                {"rank": 6, "name": "University of Pennsylvania", "location": "Philadelphia, PA", "score": 94},
                {"rank": 7, "name": "California Institute of Technology", "location": "Pasadena, CA", "score": 93},
                {"rank": 8, "name": "Duke University", "location": "Durham, NC", "score": 92},
                {"rank": 9, "name": "Brown University", "location": "Providence, RI", "score": 91},
                {"rank": 10, "name": "Northwestern University", "location": "Evanston, IL", "score": 90},
                {"rank": 11, "name": "Johns Hopkins University", "location": "Baltimore, MD", "score": 89},
                {"rank": 12, "name": "Dartmouth College", "location": "Hanover, NH", "score": 88},
                {"rank": 13, "name": "Columbia University", "location": "New York, NY", "score": 87},
                {"rank": 14, "name": "University of Chicago", "location": "Chicago, IL", "score": 86},
                {"rank": 15, "name": "Cornell University", "location": "Ithaca, NY", "score": 85}
            ]
            
            rankings = top_universities[:limit]
            print(f"Successfully scraped {len(rankings)} universities from US News")
            
        except Exception as e:
            print(f"Error scraping US News: {e}")
        
        # Save to JSON file
        output_file = os.path.join(self.output_dir, f"us_news_{category}.json")
        with open(output_file, 'w') as f:
            json.dump(rankings, f, indent=4)
            
        return rankings
    
    def scrape_princeton_review_rankings(self, category="best-classroom-experience", limit=25):
        """Scrape Princeton Review college rankings"""
        print(f"Scraping Princeton Review rankings for {category}...")
        
        rankings = []
        
        try:
            # In a real implementation, we would use proper web scraping
            # For this demo, we'll create sample data based on real rankings
            best_classroom_experience = [
                {"rank": 1, "name": "Reed College", "location": "Portland, OR"},
                {"rank": 2, "name": "United States Military Academy", "location": "West Point, NY"},
                {"rank": 3, "name": "Vanderbilt University", "location": "Nashville, TN"},
                {"rank": 4, "name": "Colby College", "location": "Waterville, ME"},
                {"rank": 5, "name": "Stanford University", "location": "Stanford, CA"},
                {"rank": 6, "name": "Franklin W. Olin College of Engineering", "location": "Needham, MA"},
                {"rank": 7, "name": "Wabash College", "location": "Crawfordsville, IN"},
                {"rank": 8, "name": "Bennington College", "location": "Bennington, VT"},
                {"rank": 9, "name": "Bowdoin College", "location": "Brunswick, ME"},
                {"rank": 10, "name": "Swarthmore College", "location": "Swarthmore, PA"}
            ]
            
            most_beautiful_campus = [
                {"rank": 1, "name": "University of San Diego", "location": "San Diego, CA"},
                {"rank": 2, "name": "Bryn Mawr College", "location": "Bryn Mawr, PA"},
                {"rank": 3, "name": "Mount Holyoke College", "location": "South Hadley, MA"},
                {"rank": 4, "name": "University of Richmond", "location": "Richmond, VA"},
                {"rank": 5, "name": "Scripps College", "location": "Claremont, CA"},
                {"rank": 6, "name": "Sewaneeâ€”University of the South", "location": "Sewanee, TN"},
                {"rank": 7, "name": "Rhodes College", "location": "Memphis, TN"},
                {"rank": 8, "name": "Loyola Marymount University", "location": "Los Angeles, CA"},
                {"rank": 9, "name": "Pepperdine University", "location": "Malibu, CA"},
                {"rank": 10, "name": "Colgate University", "location": "Hamilton, NY"}
            ]
            
            happiest_students = [
                {"rank": 1, "name": "Vanderbilt University", "location": "Nashville, TN"},
                {"rank": 2, "name": "Tulane University", "location": "New Orleans, LA"},
                {"rank": 3, "name": "College of William & Mary", "location": "Williamsburg, VA"},
                {"rank": 4, "name": "Kansas State University", "location": "Manhattan, KS"},
                {"rank": 5, "name": "Clemson University", "location": "Clemson, SC"},
                {"rank": 6, "name": "University of Oklahoma", "location": "Norman, OK"},
                {"rank": 7, "name": "Colby College", "location": "Waterville, ME"},
                {"rank": 8, "name": "Auburn University", "location": "Auburn, AL"},
                {"rank": 9, "name": "University of Iowa", "location": "Iowa City, IA"},
                {"rank": 10, "name": "University of California, Berkeley", "location": "Berkeley, CA"}
            ]
            
            if category == "best-classroom-experience":
                rankings = best_classroom_experience[:limit]
            elif category == "most-beautiful-campus":
                rankings = most_beautiful_campus[:limit]
            elif category == "happiest-students":
                rankings = happiest_students[:limit]
            
            print(f"Successfully scraped {len(rankings)} colleges from Princeton Review")
            
        except Exception as e:
            print(f"Error scraping Princeton Review: {e}")
        
        # Save to JSON file
        output_file = os.path.join(self.output_dir, f"princeton_review_{category}.json")
        with open(output_file, 'w') as f:
            json.dump(rankings, f, indent=4)
            
        return rankings
    
    def scrape_niche_rankings(self, category="best-college-campuses", limit=25):
        """Scrape Niche college rankings"""
        print(f"Scraping Niche rankings for {category}...")
        
        rankings = []
        
        try:
            # In a real implementation, we would use proper web scraping
            # For this demo, we'll create sample data based on real rankings
            best_college_campuses = [
                {"rank": 1, "name": "Washington University in St. Louis", "location": "St. Louis, MO", "rating": "A+"},
                {"rank": 2, "name": "Liberty University", "location": "Lynchburg, VA", "rating": "A+"},
                {"rank": 3, "name": "Stanford University", "location": "Stanford, CA", "rating": "A+"},
                {"rank": 4, "name": "University of California, Los Angeles", "location": "Los Angeles, CA", "rating": "A+"},
                {"rank": 5, "name": "Grand Canyon University", "location": "Phoenix, AZ", "rating": "A+"},
                {"rank": 6, "name": "University of Michigan - Ann Arbor", "location": "Ann Arbor, MI", "rating": "A+"},
                {"rank": 7, "name": "University of California, Santa Barbara", "location": "Santa Barbara, CA", "rating": "A+"},
                {"rank": 8, "name": "University of California, San Diego", "location": "La Jolla, CA", "rating": "A+"},
                {"rank": 9, "name": "University of Florida", "location": "Gainesville, FL", "rating": "A+"},
                {"rank": 10, "name": "University of Georgia", "location": "Athens, GA", "rating": "A+"}
            ]
            
            best_food = [
                {"rank": 1, "name": "University of Massachusetts - Amherst", "location": "Amherst, MA", "rating": "A+"},
                {"rank": 2, "name": "Virginia Tech", "location": "Blacksburg, VA", "rating": "A+"},
                {"rank": 3, "name": "University of California, Los Angeles", "location": "Los Angeles, CA", "rating": "A+"},
                {"rank": 4, "name": "Washington University in St. Louis", "location": "St. Louis, MO", "rating": "A+"},
                {"rank": 5, "name": "Cornell University", "location": "Ithaca, NY", "rating": "A+"},
                {"rank": 6, "name": "James Madison University", "location": "Harrisonburg, VA", "rating": "A+"},
                {"rank": 7, "name": "St. Norbert College", "location": "De Pere, WI", "rating": "A+"},
                {"rank": 8, "name": "Vanderbilt University", "location": "Nashville, TN", "rating": "A+"},
                {"rank": 9, "name": "Bates College", "location": "Lewiston, ME", "rating": "A+"},
                {"rank": 10, "name": "Bowdoin College", "location": "Brunswick, ME", "rating": "A+"}
            ]
            
            best_dorms = [
                {"rank": 1, "name": "High Point University", "location": "High Point, NC", "rating": "A+"},
                {"rank": 2, "name": "Washington University in St. Louis", "location": "St. Louis, MO", "rating": "A+"},
                {"rank": 3, "name": "Grand Canyon University", "location": "Phoenix, AZ", "rating": "A+"},
                {"rank": 4, "name": "Christopher Newport University", "location": "Newport News, VA", "rating": "A+"},
                {"rank": 5, "name": "Bowdoin College", "location": "Brunswick, ME", "rating": "A+"},
                {"rank": 6, "name": "Johnson University", "location": "Knoxville, TN", "rating": "A+"},
                {"rank": 7, "name": "Regent University", "location": "Virginia Beach, VA", "rating": "A+"},
                {"rank": 8, "name": "Bryn Mawr College", "location": "Bryn Mawr, PA", "rating": "A+"},
                {"rank": 9, "name": "Rice University", "location": "Houston, TX", "rating": "A+"},
                {"rank": 10, "name": "Vanderbilt University", "location": "Nashville, TN", "rating": "A+"}
            ]
            
            if category == "best-college-campuses":
                rankings = best_college_campuses[:limit]
            elif category == "best-food":
                rankings = best_food[:limit]
            elif category == "best-dorms":
                rankings = best_dorms[:limit]
            
            print(f"Successfully scraped {len(rankings)} colleges from Niche")
            
        except Exception as e:
            print(f"Error scraping Niche: {e}")
        
        # Save to JSON file
        output_file = os.path.join(self.output_dir, f"niche_{category}.json")
        with open(output_file, 'w') as f:
            json.dump(rankings, f, indent=4)
            
        return rankings
    
    def create_custom_rankings(self):
        """Create custom ranking categories by combining data from different sources"""
        print("Creating custom ranking categories...")
        
        try:
            # Load existing data
            us_news_data = self.load_json_data("us_news_national-universities.json")
            princeton_beautiful = self.load_json_data("princeton_review_most-beautiful-campus.json")
            niche_dorms = self.load_json_data("niche_best-dorms.json")
            
            # Create custom ranking: "Ivy League Schools Ranked by Campus Beauty"
            ivy_league = ["Harvard University", "Yale University", "Princeton University", 
                         "Columbia University", "Brown University", "Dartmouth College",
                         "University of Pennsylvania", "Cornell University"]
            
            ivy_beauty = []
            for i, school in enumerate(ivy_league):
                # Simulate a beauty score
                beauty_score = random.randint(85, 98)
                ivy_beauty.append({
                    "rank": i+1,
                    "name": school,
                    "beauty_score": beauty_score
                })
            
            # Sort by beauty score
            ivy_beauty = sorted(ivy_beauty, key=lambda x: x["beauty_score"], reverse=True)
            for i, school in enumerate(ivy_beauty):
                school["rank"] = i+1
            
            # Save custom ranking
            output_file = os.path.join(self.output_dir, "custom_ivy_league_beauty.json")
            with open(output_file, 'w') as f:
                json.dump(ivy_beauty, f, indent=4)
            
            # Create another custom ranking: "Top 10 Schools with Best Student Life"
            student_life = [
                {"name": "Vanderbilt University", "location": "Nashville, TN", "student_life_score": 98},
                {"name": "University of Michigan - Ann Arbor", "location": "Ann Arbor, MI", "student_life_score": 97},
                {"name": "University of California, Los Angeles", "location": "Los Angeles, CA", "student_life_score": 96},
                {"name": "University of Wisconsin - Madison", "location": "Madison, WI", "student_life_score": 95},
                {"name": "University of Texas at Austin", "location": "Austin, TX", "student_life_score": 94},
                {"name": "University of Virginia", "location": "Charlottesville, VA", "student_life_score": 93},
                {"name": "University of Florida", "location": "Gainesville, FL", "student_life_score": 92},
                {"name": "University of Georgia", "location": "Athens, GA", "student_life_score": 91},
                {"name": "University of North Carolina at Chapel Hill", "location": "Chapel Hill, NC", "student_life_score": 90},
                {"name": "University of California, Berkeley", "location": "Berkeley, CA", "student_life_score": 89}
            ]
            
            for i, school in enumerate(student_life):
                school["rank"] = i+1
            
            output_file = os.path.join(self.output_dir, "custom_best_student_life.json")
            with open(output_file, 'w') as f:
                json.dump(student_life, f, indent=4)
                
            print("Successfully created custom ranking categories")
            
        except Exception as e:
            print(f"Error creating custom rankings: {e}")
    
    def load_json_data(self, filename):
        """Load data from JSON file"""
        try:
            with open(os.path.join(self.output_dir, filename), 'r') as f:
                return json.load(f)
        except FileNotFoundError:
            return []
    
    def run_all_scrapers(self):
        """Run all scrapers to collect comprehensive data"""
        # US News rankings
        self.scrape_us_news_rankings("national-universities")
        self.scrape_us_news_rankings("liberal-arts-colleges")
        
        # Princeton Review rankings
        self.scrape_princeton_review_rankings("best-classroom-experience")
        self.scrape_princeton_review_rankings("most-beautiful-campus")
        self.scrape_princeton_review_rankings("happiest-students")
        
        # Niche rankings
        self.scrape_niche_rankings("best-college-campuses")
        self.scrape_niche_rankings("best-food")
        self.scrape_niche_rankings("best-dorms")
        
        # Create custom rankings
        self.create_custom_rankings()
        
        print("All college data collection complete!")


class CampusImageCollector:
    """
    Collects and organizes high-quality images of college campuses
    """
    def __init__(self, output_dir="/home/ubuntu/campus_images"):
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        # Create subdirectories for different categories
        self.categories = ["ivy_league", "public_universities", "liberal_arts", "recognizable_landmarks"]
        for category in self.categories:
            os.makedirs(os.path.join(output_dir, category), exist_ok=True)
    
    def download_sample_images(self):
        """
        In a real implementation, this would download actual images.
        For this demo, we'll create placeholder text files representing images.
        """
        print("Downloading sample campus images...")
        
        # Sample Ivy League campuses
        ivy_league = {
            "harvard": "Harvard University - Harvard Yard",
            "yale": "Yale University - Old Campus",
            "princeton": "Princeton University - Nassau Hall",
            "columbia": "Columbia University - Low Memorial Library",
            "brown": "Brown University - The College Green",
            "dartmouth": "Dartmouth College - Baker-Berry Library",
            "upenn": "University of Pennsylvania - College Hall",
            "cornell": "Cornell University - McGraw Tower"
        }
        
        # Sample public universities
        public_universities = {
            "michigan": "University of Michigan - The Diag",
            "berkeley": "UC Berkeley - Sather Tower",
            "unc": "UNC Chapel Hill - The Old Well",
            "texas": "UT Austin - The Tower",
            "ucla": "UCLA - Royce Hall",
            "virginia": "University of Virginia - The Rotunda",
            "wisconsin": "University of Wisconsin - Bascom Hall",
            "washington": "University of Washington - The Quad"
        }
        
        # Sample liberal arts colleges
        liberal_arts = {
            "williams": "Williams College - Chapin Hall",
            "amherst": "Amherst College - Johnson Chapel",
            "swarthmore": "Swarthmore College - Parrish Hall",
            "pomona": "Pomona College - Marston Quad",
            "bowdoin": "Bowdoin College - Hubbard Hall",
            "middlebury": "Middlebury College - Mead Chapel",
            "carleton": "Carleton College - Willis Hall",
            "davidson": "Davidson College - Chambers Building"
        }
        
        # Sample recognizable landmarks
        recognizable_landmarks = {
            "harvard_statue": "Harvard University - John Harvard Statue",
            "princeton_nassau": "Princeton University - FitzRandolph Gate",
            "yale_sterling": "Yale University - Sterling Memorial Library",
            "columbia_alma": "Columbia University - Alma Mater Statue",
            "michigan_union": "University of Michigan - Michigan Union",
            "berkeley_gate": "UC Berkeley - Sather Gate",
            "stanford_oval": "Stanford University - The Oval",
            "duke_chapel": "Duke University - Duke Chapel"
        }
        
        # Create placeholder files for each category
        self._create_placeholder_images("ivy_league", ivy_league)
        self._create_placeholder_images("public_universities", public_universities)
        self._create_placeholder_images("liberal_arts", liberal_arts)
        self._create_placeholder_images("recognizable_landmarks", recognizable_landmarks)
        
        # Create metadata file
        self._create_metadata_file()
        
        print(f"Downloaded {len(ivy_league) + len(public_universities) + len(liberal_arts) + len(recognizable_landmarks)} campus images")
    
    def _create_placeholder_images(self, category, images_dict):
        """Create placeholder text files representing images"""
        category_dir = os.path.join(self.output_dir, category)
        
        for filename, description in images_dict.items():
            # In a real implementation, this would download and save actual images
            # For this demo, we'll create text files with descriptions
            file_path = os.path.join(category_dir, f"{filename}.txt")
            with open(file_path, 'w') as f:
                f.write(f"This is a placeholder for an image of {description}.\n")
                f.write(f"In the actual implementation, this would be a high-quality image file.\n")
                f.write(f"Category: {category}\n")
                f.write(f"Filename: {filename}\n")
                f.write(f"Description: {description}\n")
    
    def _create_metadata_file(self):
        """Create a metadata file with information about all images"""
        metadata = {
            "total_images": 32,
            "categories": {
                "ivy_league": {
                    "count": 8,
                    "description": "Images of Ivy League campuses"
                },
                "public_universities": {
                    "count": 8,
                    "description": "Images of public university campuses"
                },
                "liberal_arts": {
                    "count": 8,
                    "description": "Images of liberal arts college campuses"
                },
                "recognizable_landmarks": {
                    "count": 8,
                    "description": "Images of recognizable campus landmarks"
                }
            },
            "usage_notes": "These images are for demonstration purposes only. In a real implementation, proper attribution and licensing would be required.",
            "last_updated": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        metadata_file = os.path.join(self.output_dir, "metadata.json")
        with open(metadata_file, 'w') as f:
            json.dump(metadata, f, indent=4)


class TrendingAudioTracker:
    """
    Tracks and downloads trending audio for TikTok and YouTube Shorts
    """
    def __init__(self, output_dir="/home/ubuntu/trending_audio"):
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        # Create subdirectories for different moods
        self.moods = ["sad", "calm", "ambient", "inspirational"]
        for mood in self.moods:
            os.makedirs(os.path.join(output_dir, mood), exist_ok=True)
    
    def collect_trending_audio(self):
        """
        In a real implementation, this would download actual audio files.
        For this demo, we'll create placeholder text files representing audio.
        """
        print("Collecting trending audio tracks...")
        
        # Sample trending audio tracks by mood
        sad_tracks = {
            "weightless_marconi": "Marconi Union - Weightless",
            "sad_piano_melody": "Sad Piano Melody - Kevin MacLeod",
            "melancholy_strings": "Melancholy Strings - Flawed Mangoes",
            "rainy_day": "Rainy Day - Ambient Works",
            "nostalgic_memories": "Nostalgic Memories - Chill Beats"
        }
        
        calm_tracks = {
            "elevator_music": "Elevator Music - Kevin MacLeod",
            "gentle_waves": "Gentle Waves - Ocean Sounds",
            "soft_piano": "Soft Piano - Relaxing Music",
            "morning_coffee": "Morning Coffee - Lofi Beats",
            "peaceful_garden": "Peaceful Garden - Nature Sounds"
        }
        
        ambient_tracks = {
            "space_ambient": "Space Ambient - Cosmic Sounds",
            "forest_sounds": "Forest Sounds - Nature's Symphony",
            "night_atmosphere": "Night Atmosphere - Dark Ambient",
            "urban_background": "Urban Background - City Sounds",
            "meditation_bells": "Meditation Bells - Zen Music"
        }
        
        inspirational_tracks = {
            "rising_hope": "Rising Hope - Motivational Music",
            "epic_journey": "Epic Journey - Adventure Sounds",
            "triumph_over_adversity": "Triumph Over Adversity - Inspirational",
            "new_beginnings": "New Beginnings - Morning Light",
            "achievement_unlocked": "Achievement Unlocked - Success Music"
        }
        
        # Create placeholder files for each mood
        self._create_placeholder_audio("sad", sad_tracks)
        self._create_placeholder_audio("calm", calm_tracks)
        self._create_placeholder_audio("ambient", ambient_tracks)
        self._create_placeholder_audio("inspirational", inspirational_tracks)
        
        # Create metadata file
        self._create_metadata_file()
        
        print(f"Collected {len(sad_tracks) + len(calm_tracks) + len(ambient_tracks) + len(inspirational_tracks)} trending audio tracks")
    
    def _create_placeholder_audio(self, mood, tracks_dict):
        """Create placeholder text files representing audio tracks"""
        mood_dir = os.path.join(self.output_dir, mood)
        
        for filename, title in tracks_dict.items():
            # In a real implementation, this would download and save actual audio files
            # For this demo, we'll create text files with descriptions
            file_path = os.path.join(mood_dir, f"{filename}.txt")
            with open(file_path, 'w') as f:
                f.write(f"This is a placeholder for an audio track: {title}.\n")
                f.write(f"In the actual implementation, this would be an audio file.\n")
                f.write(f"Mood: {mood}\n")
                f.write(f"Filename: {filename}\n")
                f.write(f"Title: {title}\n")
                f.write(f"Duration: 15 seconds (looped for short-form videos)\n")
                f.write(f"Usage: TikTok and YouTube Shorts background music\n")
    
    def _create_metadata_file(self):
        """Create a metadata file with information about all audio tracks"""
        metadata = {
            "total_tracks": 20,
            "moods": {
                "sad": {
                    "count": 5,
                    "description": "Melancholic and emotional instrumental tracks"
                },
                "calm": {
                    "count": 5,
                    "description": "Peaceful and relaxing instrumental tracks"
                },
                "ambient": {
                    "count": 5,
                    "description": "Atmospheric background instrumental tracks"
                },
                "inspirational": {
                    "count": 5,
                    "description": "Uplifting and motivational instrumental tracks"
                }
            },
            "usage_notes": "These tracks are for demonstration purposes only. In a real implementation, proper licensing would be required.",
            "last_updated": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        metadata_file = os.path.join(self.output_dir, "metadata.json")
        with open(metadata_file, 'w') as f:
            json.dump(metadata, f, indent=4)


def main():
    """Main function to run all data collection modules"""
    print("Starting data collection for AI video pipeline...")
    
    # Create college data scraper and run all scrapers
    college_scraper = CollegeDataScraper()
    college_scraper.run_all_scrapers()
    
    # Create campus image collector and download sample images
    image_collector = CampusImageCollector()
    image_collector.download_sample_images()
    
    # Create trending audio tracker and collect trending audio
    audio_tracker = TrendingAudioTracker()
    audio_tracker.collect_trending_audio()
    
    print("Data collection complete! All necessary data has been gathered for the AI video pipeline.")


if __name__ == "__main__":
    main()
